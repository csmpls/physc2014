\section{\uppercase{Related Work}}
\label{sec:related}

\subsection{Calibrating EEG-based BCI}

\noindent BCI systems generally aim to recognize a user's mental gestures as one of a finite set of discrete symbols, a problem that can be thought of as a pattern recognition task \cite{lotte_review_2007}. The difficulty of this task stems primarily from the variable and non-stationary nature of neural signals: the ``symbols" we wish to identify are expressed differently between individuals, and even vary within individuals from trial to trial \cite{vidaurre_fully_2006,vidaurre_machine-learning-based_2011}. 

In order to compensate for variability in BCI signals, recent work has leveraged adaptive classification algorithms to distinguish between mental gestures \cite{lotte_review_2007,vidaurre_machine-learning-based_2011}. Automated calibration procedures have turned BCI novices into competent users over the course of hours instead of days or weeks, and without manual calibration by a researcher \cite{vidaurre_fully_2006,vidaurre_co-adaptive_2011,vidaurre_machine-learning-based_2011, friedrich_whatever_2013}. During calibration, users perform ``labeled'' (that is, known) mental gestures in order to produce samples for the classifier. Meanwhile, the classifier attempts to determine which features of the data are most informative. 

\subsection{Statistical Signal Processing in EEG-based BCI}

Calibrating a BCI requires an algorithm that can adapt to its inputs. Support vector machines (SVM) are a set of supervised machine learning methods that take labeled example data to create a model that can be used to predict the classes of unlabeled data. SVMs use a hyperplane (an \emph{n}-dimensional construct in an \emph{n}+1 dimensional space) to draw discriminatory boundaries between classes. 

Past work has used linear SVMs in BCI applications with great success \cite{garrett_comparison_2003,grierson_better_2011}. In contrast to linear discriminant analysis, which also have a long history of use in BCI, SVMs select the hyperplane that maximizes distance from the nearest training points, which has been shown to increase the model's generalizability \cite{burges_tutorial_1998}. 

In classification algorithms generally, larger feature vectors require an exponential increase in the amount of data needed to describe classes, a property known as ``the curse of dimensionality'' \cite{jain_statistical_2000}. Traditionally, BCI applications rely on dense, high-dimensional feature vectors produced by multi-electrode scanning caps with high temporal resolution, so dimensionality represents a major bottleneck in training classification algorithms. This bottleneck threatens the responsiveness of BCI from a user experience standpoint and places high requirements on end users' hardware.

\subsection{Brain-Computer Interface ``in the Wild''}

\noindent In recent years, numerous inexpensive, mobile EEG devices have come to the consumer brainwave sensing market. Compared to their lab-based counterparts, these devices have significantly fewer electrodes and therefore much lower spatial resolution. Most of them also employ dry contact electrodes, which can produce significantly noisier signals \cite{de2014mobile}. Nonetheless, researchers have demonstrated several mobile-ready BCI systems that use these devices to detect emotional states, event-related potentials (ERP), and demonstrate the feasibility of brainwave-based biometric authentication \cite{crowley_evaluating_2010,grierson_better_2011,adams_i_2013}.

% the Neurosky MindSet in particular (the headset used in this study - a single, dry EEG electrode placed roughly at FP2, which connects wirelessly to phones and computers, and sells for roughly 100USD) has been used to successfully detect emotional states, event-related potentials (ERP), and to employ brain-based biometric authentication \cite{crowley_evaluating_2010,grierson_better_2011,adams_i_2013}.  

However, the use of consumer EEGs for the direct, real-time control of software interfaces has proven more difficult, as the number of electrodes on these headsets limit the spatial resolution required to discriminate between mental gestures \cite{carrino_self-paced_2012,larsen_classification_2011}. While we expect continued improvements in successive generations of consumer-grade EEG devices, the signal from these devices will remain noisier than the lab-based counterparts, as users will be wearing and using them in everyday settings, with ambient electromagnetic signals interfering with endogenous bio-signals.

To transition BCI from the lab into naturalistic environments, we must squeeze more signal out of fewer, and less reliable, sensors. Furthermore, since BCIs are envisioned largely as always-available input devices, they will likely be deployed on mobile processors and perhaps even embedded processing systems. Thus, the available computational resources may be more comparable to that of a smartphone than of a desktop workstation. Furthermore, it is feasible that we may need to do some processing ``in the cloud'' (i.e., on a more powerful server to which the client sends data over the network, similar to the way Apple's Siri processes voice data). For effective BCI to occur in these environments, we must extract signal in a maximally efficient way so as to limit our computational footprint, and perhaps even to minimize the size of data if we wish to ship it to an external server.

%\subsection{Online, co-adaptive calibration}

%\noindent 

% \subsection{Co-adaptive BCI in naturalistic settings}

% thomas's note on "change for the same subject over time": Since you have mentioned this issue in the manuscript, you might want to test robustness of our classifier over two different sessions. If remember well, we have data for this.
% \noindent For the control of interface systems, it is crucial that mental gestures be actuated intentionally, and that the system's interpretation be immediately verifiable by the user. \cite{mcfarland_brain-computer_2011} \textit{Maybe a line here about how the system needs to be fast for responsiveness} Efficient calibration is particularly crucial for real-world use, as EEG signals vary between subjects, and could even change within the same subject over time. From a technical standpoint, calibration amounts to the training and re-training of one or several adaptive algorithms. Calibration can be processing-intensive on a mobile device, especially if the system is computing multiple candidate models. This requires a great deal of online signal processing, which entails not only the computational time required to train the classifier but also the space required to handle the data and the time required to read and write the data from memory or from disk.

% drop another hint about embedded sensors and doing stuff in the cloud

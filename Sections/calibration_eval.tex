\section{\uppercase{Progressive strategy for calibrating a binary BCI}}
\label{sec:calibration_eval}

\noindent In the previous section, we find that our compression technique can speed up an SVM classifier without significant detriment to BCI accuracy. However, it must also allow users to quickly calibrate the system to their personal physiological signals.

In this section, we evaluate a strategy for user calibration in which mental gestures are recorded progressively on an ``as needed'' basis. Using the logarithmic binning method to produce quantized signals with a resolution of 100 bins, we measure user calibration time (the time it takes a user to achieve a threshold accuracy with the BCI) and the classification accuracy each user achieves after calibration. 

Our calibration strategy takes sixty-second sample recordings of mental gestures and splices them into 120 $\sfrac{1}{2}$-second chunks. By performing seven-fold cross-validation on sample data from a pair of mental gestures, we make an estimate of how easily discriminable these gestures are by our classifier. With this technique, we need only test only the most promising (highest-performing) of candidate gesture pairs for further testing.

In addition, we seek to minimize the amount of time users spend recording samples of mental gestures. One way to minimize this time is to first test the subset of gestures most likely to yield strong performance. For each subject, we perform an exhaustive search of the 21 best-performing gesture pairs and record the frequency of each task's occurrence in a best-case task pair (Table \ref{table:name}). Assuming that we can establish a consistent ordering of best-performing mental gestures for a target population, we could prompt users to recording new samples progressively, using this data to inform the order in which our calibration strategy would prompt the user to perform the gestures.

% this is where i put a table of tasks correlated with bestcase performance and a quick description, how we generated those data and what we need them for

\begin{table}[!h]
%  \vspace{-0.2cm}
  \centering
  \begin{tabular}{ | l | l | l | p{5cm} |}
  \hline
  Task & Frequency \\ \hline
  \textit{color} & 10 \\ \hline
  \textit{breathing} & 5 \\ \hline
  \textit{pass} & 4 \\ \hline
  \textit{sport} & 3 \\ \hline
  \textit{finger} & 2 \\ \hline
  \textit{song} & 2 \\ \hline
  \textit{audio} & 2 \\ \hline
  \end{tabular}
  \caption{Frequency of each mental task's occurrence in a task pair that achieves a highest classification accuracy.}
  \label{table:name}
%  \vspace{-0.1cm}
\end{table}

The opportunistic strategy starts with three tasks most commonly associated with best-case performance (\textit{color}, \textit{breathing}, \textit{pass}) for an initial user calibration time of 120 seconds (40 seconds per task). We then cross-validate every permutation of two of these tasks (i.e., \textit{color} versus \textit{breathing}, \textit{color} versus \textit{pass}, \textit{breathing} versus \textit{pass}). The task pair with the highest mean score across cross-validation rounds is selected for an additional testing session, in which the remaining 80 seconds of recordings for both tasks are used to generate an estimate of the classifier's accuracy on new EEG signals.

If the score on this additional testing round is below 75\%, a commonly used threshold for BCI literacy \cite{vidaurre_towards_2010}, the user will be prompted to record sixty seconds of the next candidate mental task. We repeat the above process on unexplored tasks until a task pair achieves over 75\% accuracy on post-calibration data, or until all tasks have been evaluated.

%\subsection{Results}

For the given set of seven candidate mental tasks, the baseline exhaustive search strategy requires 2100 seconds of calibration time and produces an average accuracy of 92.5\% across subjects (\textit{$\sigma$} = 0.09). Our opportunistic strategy takes an average of 374.6 seconds of calibration time (\textit{$\sigma$} = 52.2) and produces an average accuracy of 88.3\% (\textit{$\sigma$} = 0.11).

Figure \ref{fig:calibration_results} shows the results from a subject's perspective. Out of 15 subjects, the opportunistic calibration strategy allows 73.6\% (11 subjects) to be calibrated in under 5 minutes, and 86.6\% (13 subjects) in under 6 minutes. The remaining two subjects were calibrated in 11 minutes and 22 minutes, respectively. All 15 subjects achieve a minimum of 75\% classification accuracy. Six subjects (40\%) achieve 100\% accuracy.

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/3.png, width = 5.5cm}}
  \caption{Calibration time across subjects (top) and classifier accuracy (bottom). The vast majority of subjects achieve acceptable accuracy in under five minutes of training, and all subjects achieve BCI literacy in under 15 minutes. }
  \label{fig:calibration_results}
  \vspace{-0.1cm}
\end{figure}

We find that our strategy calibrates users to BCI control significantly more quickly than an exhaustive search, finding support for H1 at the \textit{p} \textless 0.001 level. On the other hand, we do not find a statistically significant difference in per-user accuracy between an opportunistic strategy and an exhaustive search (\textit{p} = 0.264). Thus, we find no support for H2.


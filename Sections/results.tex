\section{\uppercase{Experiments}}

\subsection{Finding a compromise between data compression and classifier accuracy}

In order to build physiological computing systems suitable for real-world use, we seek to maxmize the system's classification accuracy while minimizing its computational requirements.

In this experiment, we examine the effect of data resolution, operationalized by the number of bins in the quantization step, on our BCI's performance, operationalized by the SVM's training time and by the SVM's estimated accuracy. 

We hypothesize that SVM accuracy will decrease with resolution, as will SVM training time.

For each subject, we generated every pair of two tasks and cross-validated our SVM seven times on recordings for those two tasks. We used ScikitLearn's built-in cross-validation toolkit, which performs each of the seven cross-validation steps using different splits of trial data in the training and testing sets. We varied the number of bins in the samples we fed to the SVM and the length of recordings (a slice of our original recording from one second to 1+n seconds). For every task pair processed, we recorded mean classification accuracy across all cross-validation trials.

As an additional performance audit, we timed our SVM at training time and testing time. In this measure, we fit an SVM to all the data for two task-pairs from five randomly-selected subjects, and repeated this process ten thousand times at different bin sizes and different lengths, collecting the minimum time observed in each series of attempts. In order to establish a proper estimate, we time the SVM after all data has been loaded to memory, disregarding the time it takes to load the data from disk.

\subsection{Results}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1a.png, width = 6cm}}
  \caption{Mean best-case accuracy among all subjects compared to time needed to train the classifier. At over 100 bins, we find no evidence of an increase in classification accuracy, which plateaus at around 95\%. }
  \label{fig:fig1a}
  \vspace{-0.1cm}
 \end{figure}

 \begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1b.png, width = 6cm}}
  \caption{Log of mean classifier training time compared to log of number of bins in data. The time needed to train the classifier decreases logarithmically as the number of bins decrease.}
  \label{fig:fig1b}
  \vspace{-0.1cm}
 \end{figure}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1c.png, width = 6cm}}
  \caption{ By decreasing the number of bins in the EEG data, we can decrease the time needed to train the support vector machine up to nine times without without detriment to classifier accuracy. }
  \label{fig:fig1c}
  \vspace{-0.1cm}
 \end{figure}

We ran an ordinary least squares regression on number of bins and classifier accuracy at recording lengths of four seconds. Number of bins was positively correlated with classifier accuracy, with each bin correpsonding to 1.13\% gain in accuracy (R-squared = .773, p \textless .001). 

We ran an additional ordinary least squares regression on number of bins in the EEG data and the time it takes to train an SVM on those data, again at recordings of four seconds. Number of bins was positively correlated with time to train classifier (slope = 0.5 R-squared = .947, p \textless .001).

Since bin size has a linear relationship with both accuracy and SVM training time, we compare accuracy and training time directly in Figure 1. 

Overall, we find that relatively small feature vectors (75-100 bins) produced with our method yield classifiers as accurate as those that use much higher resolution samples, and that reducing vector size in this way can dramatically increase the computational speed of training the BCI's support vector machine. 


\subsection{Opportunistic strategy for calibrating a binary BCI}

In the previous experiment, we found a maximum level of data compression that preserves SVM accuracy while significantly speeding up SVM training time. However, 

In this experiment, we evaluate this level of compression in the context of a user calibration strategy. Using recordings from our dataset, we evaluate the amount of user calibration time needed to acheive a BCI accuracy of over 75\%.

For each subject, we spliced all recordings into 0.5-second chunks, each one representing a single power spectrum reading from our headset. We begin with sixty seconds of recording from the three tasks most commonly associated with best-case performance (base, pass, color) for an initial user calibration time of 120 seconds. We then perform a seven-fold cross-validation on every permutation of two of these tasks (base versus task, pass versus task, pass versus color, etc). The taskpair with the highest mean score across all seven cross-validations is selected for a more robust calibration, in which the reamining 80 seconds of recordings for both tasks are used to validate the SVM. If the score on this validation round is below 75\%, we add the first 60 seconds of recording from the taskpair that was next most correlated with bestcase accuracy. 

This process is repeated until all taskpairs are added, or until one taskpair acheives over 75\% accuracy on after-calibration data. We record the accuracy achieved among subjects and the number of seconds of calibration data required to achieve the resulting accuracy.

\subsection{Results}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/3.png, width = 5.5cm}}
  \caption{Calibration time across subjects (top) and classifier accuracy (bottom). The vast majority of subjects acheive acceptable accuracy in under five minutes of training, and all subjects acheive BCI literacy in under 15 minutes. }
  \label{fig:fig2}
  \vspace{-0.1cm}
\end{figure}






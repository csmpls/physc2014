\section{\uppercase{The effect of quantization technique on classifier speed and accuracy}}


Generally, we seek to maxmize our system's classification accuracy while minimizing its computational expense. One way to reduce the computational requirements of a SVM classifier is to reduce the size of the feature vectors on which it is trained and tested. Our signal quantization method allows us to directly adjust the size of feature vectors by changing the signal's resolution (see 3.1), though lowering the resolution of feature vectors could negatively effect the classifier's performance.

In this experiment, we examine the effect of resolution, operationalized by the number of bins used in the quantization step, on our BCI's performance, operationalized by the SVM's training time and by the SVM's estimated accuracy. 

H1: SVM accuracy will decrease with resolution.
H2: SVM training time will decrease with resolution.

\subsection{Protocol}

For each subject, we generate every pair of two tasks and cross-validate our SVM seven times on the recordings for this pair of tasks. We vary the resolution of the samples we feed to the SVM. For every task pair processed, we record mean classification accuracy across all rounds of cross-validation. For each subject, we record the best-performing taskpair, which corresponds to our estimation of optimal performance of the BCI for that subject.

As an additional performance audit, we measure the time needed to fit an SVM to the data for two randomly selected taskpairs across all subjects. We repeat this process ten thousand times at different resolutions, collecting the minimum time observed in each series of attempts.

\subsection{Results}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1a.png, width = 6cm}}
  \caption{Mean best-case accuracy among all subjects compared to time needed to train the classifier. At reoslutions of 100 points and greater, we find no evidence of an increase in classification accuracy. }
  \label{fig:fig1a}
  \vspace{-0.1cm}
 \end{figure}

 \begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1b.png, width = 6cm}}
  \caption{Log of mean classifier training time compared to log of data resolution. The time needed to train the classifier increases logarithmically with resolution.}
  \label{fig:fig1b}
  \vspace{-0.1cm}
 \end{figure}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/1c.png, width = 6cm}}
  \caption{ Best-case accuracy compared to the time needed to train the classifier. By decreasing the number of bins in the EEG data, we can decrease the time needed to train the support vector machine up to nine times without without significant detriment to classifier accuracy. }
  \label{fig:fig1c}
  \vspace{-0.1cm}
 \end{figure}


We find support for H1. Although resolution was positively correlated with classifier accuracy (slope = .0013 R-squared = .773, p \textless .001), this effect appears only at resolutions lower than 100 points. We find no significant increase in SVM accuracy at resolutions over 100 bins. 

Resolution was also positively correlated with time to train classifier (slope = 0.5 R-squared = .947, p \textless .001). We compare accuracy and SVM training time directly in \ref{fig:fig1c}. Thus, we find support for H2.

Overall, we find that relatively small feature vectors produced with our method (100 values) yield classifiers as accurate as full-resolution samples (1024 values), and that reducing vector size in this way can dramatically increase the computational speed of training an SVM. 

\section{\uppercase{Opportunistic strategy for calibrating a binary BCI}}

In the previous experiment, we found that our compression technique can speed up an SVM classifier without significant detriment to BCI accuracy. However, for the technique to be useful in real-world applications, it must also allow users to quickly calibrate the system to their personal physiological signals.

In this experiment, we evaluate an opportunistic strategy for user calibration. Using a resolution of 100 points identified as optimal in the previous experiment, we measure user calibration time (the time it takes a user to achieve a threshold accuracy with the BCI) and the classification accuracy each user achieves after calibration. We hypothesize that this technique will allow for faster calibration than an exhaustive search (720 seconds) while maintaining sufficient system accuracy across users.

\subsection{Protocol}

As a baseline, we perform an exhaustive search of SVM accuracy on taskpairs identified each subject's best-performing taskpair. We recorded the frequency of each task's occurrence in a best-case taskpair \ref{table:name}. We used these data to inform the order in which our opportunistic calibration strategy would prompt the user to record tasks.

We begin with examples of the three tasks most commonly associated with best-case performance (base, pass, color) for an initial user calibration time of 120 seconds. We then perform a seven-fold cross-validation on every permutation of two of these tasks (base versus task, pass versus task, pass versus color, etc). The taskpair with the highest mean score across cross-validation rounds is selected for an additional testing session, in which the reamining 80 seconds of recordings for both tasks are used to generate an estimate of the classifier's accuracy on new EEG signals.

% this is where i put a table of tasks correlated with bestcase performance and a quick description, how we generated those data and what we need them for

\begin{table}[!h]
  \vspace{-0.2cm}
  \centering
  \begin{tabular}{ | l | l | l | p{5cm} |}
  \hline
  Task & Freq Bestcase \\ \hline
  Color & 10 \\ \hline
  Base & 5 \\ \hline
  Pass & 4 \\ \hline
  Sport & 3 \\ \hline
  Finger & 2 \\ \hline
  Song & 2 \\ \hline
  Eye & 2 \\ \hline
  \end{tabular}
  \caption{An exhaustive search of SVM accuracy on taskpairs identified each subject's best-performing taskpair. We recorded the frequency of each task's occurrence in a best-case taskpair, shown here. We used these data to inform the order in which our opportunistic calibration strategy would prompt the user to record tasks.}
  \label{table:name}
  \vspace{-0.1cm}
\end{table}

If the score on this additional testing round is below 75\% (a threshold for BCI literacy) \cite{vidaurre_towards_2010}, the user records sixty seconds of the taskpair next most correlated with bestcase accuracy across users. We repeat the above process on unexplored taskpairs repeated until a taskpair acheives over 75\% accuracy on post-calibration data, or until all taskpairs have been evaluated.

H1: We hypothesize that the opportunistic calibration strategy will reach threshold accuracy in less  time than will the exhaustive search.

H2: We hypothesize that the opportunistic strategy will acheive lower accuracy than will the exhaustive method, as it could find local optima.

\subsection{Results}

\begin{figure}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = Figures/3.png, width = 5.5cm}}
  \caption{Calibration time across subjects (top) and classifier accuracy (bottom). The vast majority of subjects acheive acceptable accuracy in under five minutes of training, and all subjects acheive BCI literacy in under 15 minutes. }
  \label{fig:fig2}
  \vspace{-0.1cm}
\end{figure}

A baseline exhaustive search required 2520 seconds of calibration time and produced an average accuracy of 92.5\% across subjects (\textit{std} = .09). Our opportunistic strategy took an average of 225.3 seconds of calibration time (\textit{std} = 52.2) and produced an average accuracy of 88.3\% (\textit{std} = .11).

We find that our strategy calibrates users to BCI control significantly more quickly than an exhaustive search (\textit{p-value} < .001 ). Thus, we find support for H1. Further, we do not a statistically significant difference in per-user accuracy between an opportunistic strategy and an exhaustive search (\textit{p-value} = .264). Thus, we find no support for H2.

